{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 분류 (EfficientNet) 실습 & GradCAM\n",
    "\n",
    "https://keep-steady.tistory.com/35?category=702928\n",
    "\n",
    "- data proportion(train:valid:test) = 4784 : 598 : 605  \n",
    "\n",
    "- LJM: 821\n",
    "- YSR: 898\n",
    "- SSJ: 910\n",
    "- ACS: 855\n",
    "- LNY: 739\n",
    "- HJP: 860\n",
    "- LJS: 904\n",
    "\n",
    "reference\n",
    "- https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demos/Adversairal%20Training%20(MNIST).ipynb\n",
    " \n",
    "Adversarial attack reference\n",
    "- https://rain-bow.tistory.com/entry/Adversarial-Attack\n",
    "- https://rain-bow.tistory.com/entry/Robust-Physical-World-AttacksRP2\n",
    "- https://rain-bow.tistory.com/entry/%EC%A0%81%EB%8C%80%EC%A0%81-%EA%B3%B5%EA%B2%A9Adversarial-Attack-FGSMPGD\n",
    "\n",
    "\n",
    "220412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## down the EfficientNet&Adversarial code\n",
    "!git clone https://github.com/airobotlab/advanced_cnn.git\n",
    "!mv advanced_cnn/efficientnet_pytorch efficientnet_pytorch\n",
    "!mv advanced_cnn/adversarial_attacks_pytorch adversarial_attacks_pytorch\n",
    "!mkdir data\n",
    "!mv advanced_cnn/data.zip data/data.zip\n",
    "%cd data/\n",
    "!unzip data.zip\n",
    "%cd ..\n",
    "!mv data/data_president_small/president_label.json data/\n",
    "!rm -rf advanced_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## load ibrary\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from PIL import Image\n",
    "import PIL.Image as pilimg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## parameter\n",
    "is_Test = False\n",
    "# is_Test = True\n",
    "num_epochs = 3\n",
    "batch_size  = 128\n",
    "\n",
    "data_path = 'data/data_president_small'  # 데이터 경로, 이 안엔 CLASS가 폴더별로 정리\n",
    "label_path = 'data/president_label.json'\n",
    "save_path='test'\n",
    "\n",
    "with open(label_path) as json_file:\n",
    "    class_names = json.load(json_file)\n",
    "pprint.pprint(class_names)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print('num class : %d'%(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## prepare data\n",
    "# make dataset\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, dataloader\n",
    "\n",
    "\n",
    "transform_function = transforms.Compose([transforms.Resize((224, 224)),  # 모델 입력사이즈로 resize\n",
    "                                         transforms.ToTensor(),  # [0, 255] -> [0, 1]\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "# class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
    "dataset = datasets.ImageFolder(data_path,\n",
    "                               transform_function)\n",
    "\n",
    "# make 8:1:1 idx & dataset\n",
    "random_seed = 220103\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random_idx = list(range(0, len(dataset)))\n",
    "random.shuffle(random_idx)\n",
    "print('total data num : %d'%len(random_idx))\n",
    "print('random check : %s'%random_idx[:5])\n",
    "\n",
    "proportion = [8, 1, 1]  ## !! 이 부분을 6, 2, 2로 바꾸면 train/valid/test 비율 조정 가능\n",
    "proportion_data = [tmp*int(len(random_idx)/10) for tmp in proportion]\n",
    "# assert sum(proportion_data) == len(random_idx)  # 반올림해서 총합은 틀려진다\n",
    "\n",
    "train_idx = random_idx[:proportion_data[0]]\n",
    "valid_idx = random_idx[proportion_data[0] : proportion_data[0]+proportion_data[1]]\n",
    "test_idx  = random_idx[proportion_data[0]+proportion_data[1] :]\n",
    "\n",
    "print('data proportion(train:valid:test) = %s : %s : %s'%(len(train_idx), len(valid_idx), len(test_idx)))\n",
    "\n",
    "datasets = {}\n",
    "datasets['train'] = Subset(dataset, train_idx)\n",
    "datasets['valid'] = Subset(dataset, valid_idx)\n",
    "datasets['test']  = Subset(dataset, test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## data loader 선언\n",
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "dataloaders['test']  = torch.utils.data.DataLoader(datasets['test'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n",
    "print('batch_size : %d,  number of batch(tvt) : %d / %d / %d' % (batch_size, batch_num['train'], batch_num['valid'], batch_num['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## 데이타 체크\n",
    "import torchvision\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "num_show_img = 8\n",
    "\n",
    "# train check\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n",
    "# valid check\n",
    "inputs, classes = next(iter(dataloaders['valid']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n",
    "# test check\n",
    "inputs, classes = next(iter(dataloaders['test']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## batch의 tensor 이미지를 확인하기 위한 함수\n",
    "def check_image_from_tensor(check_image, check_class):\n",
    "    title = list(check_class.cpu().numpy())  # torch tensor to list\n",
    "    \n",
    "    # 5x1 형식으로 만들기 위해\n",
    "    num_image = len(title)\n",
    "    if num_image <= 5:\n",
    "        columns = num_image\n",
    "        rows = 1\n",
    "    else:\n",
    "        columns = 5\n",
    "        rows = int(np.ceil(num_image/columns))\n",
    "\n",
    "    fig=plt.figure(figsize=(3*columns, 4*rows))\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    for i in range(1, num_image +1):\n",
    "        inp = check_image[i-1].numpy().transpose((1, 2, 0))\n",
    "        inp = std * inp + mean  # 원본 이미지로 변환\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        \n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.title(title[i-1])\n",
    "        plt.imshow(inp)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "num_show_img = 10\n",
    "# data check\n",
    "inputs, classes = next(iter(dataloaders['test']))\n",
    "check_image, check_class = inputs[:num_show_img], classes[:num_show_img]\n",
    "check_image_from_tensor(check_image, check_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## load model\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = 'efficientnet-b0'  # b5\n",
    "num_classes = 7  # 장싱, 비정상\n",
    "freeze_extractor = True  # FC layer만 학습하고 efficientNet extractor 부분은 freeze하여 학습시간 단축, 89860 vs 4097408\n",
    "use_multi_gpu = False\n",
    "\n",
    "image_size = EfficientNet.get_image_size(model_name)\n",
    "print('model input shape : (%d x %d)'%(image_size, image_size))\n",
    "print('model output class : %d'%(num_classes))\n",
    "model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "\n",
    "# fc 제외하고 freeze\n",
    "if freeze_extractor:\n",
    "    print('extractor freeze')\n",
    "    for n, p in model.named_parameters():\n",
    "        if '_fc' not in n:\n",
    "            p.requires_grad = False\n",
    "            \n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)            \n",
    "print('학습 parameters 개수 : %d'%(count_parameters(model)))\n",
    "            \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# multi gpu(2개 이상)를 사용하는 경우\n",
    "if use_multi_gpu:\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    if (device.type=='cuda') and (num_gpu > 1):\n",
    "        print('use multi gpu : %d' % (num_gpu))\n",
    "        model = nn.DataParallel(model, device_ids=list(range(num_gpu)))\n",
    "        \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# define optimizer, criterion\n",
    "criterion = nn.CrossEntropyLoss()  # 분류이므로 cross entrophy 사용\n",
    "\n",
    "# optimizer 선언, SGD, Adam으로도 해보자\n",
    "# optimizer = optim.SGD(model.parameters(), \n",
    "#                          lr = 0.05,\n",
    "#                          momentum=0.9,\n",
    "#                          weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.98739)  # LR 스케쥴러, 점점 줄어든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# define trainer\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, is_test=False, save_path='output'):\n",
    "    since = time.time()\n",
    "\n",
    "    if not os.path.isdir(save_path):  os.makedirs(save_path)  # 저장 폴더 생성\n",
    "    # for saving best model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc, best_f1 = 0.0, 0.0\n",
    "    train_loss, train_acc, train_f1, valid_loss, valid_acc, valid_f1 = [], [], [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch %d/%d' % (epoch, num_epochs-1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "            pred_list, label_list = [], []  \n",
    "            # Iterate over data\n",
    "#             for idx, batch in tqdm(enumerate(dataloaders[phase])):\n",
    "            for idx, batch in enumerate(dataloaders[phase]):                \n",
    "\n",
    "                # for test\n",
    "                if is_test:\n",
    "                    if idx > 2: break\n",
    "\n",
    "                inputs, labels = batch  # image, label\n",
    "                inputs = inputs.to(device)  # [128, 3, 224, 224]\n",
    "                labels = labels.to(device)  # [128], tensor([1, 1, 1, 0, 1, ..])\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)  # 이미지가 입력을 때 모델을 통과하여 예측확률을 구함\n",
    "                    _, preds = torch.max(outputs, 1)  # 예측 확률 중 최대값의 index 구함\n",
    "                    loss = criterion(outputs, labels)  # 예측값과 정답 차이 비교\n",
    "\n",
    "                    # 학습시만 backpropagation, backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "\n",
    "                pred_list  += preds.data.cpu().numpy().tolist()\n",
    "                label_list += labels.data.cpu().numpy().tolist()\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = float(running_loss / num_cnt)\n",
    "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "            epoch_f1   = float(f1_score(label_list, pred_list, average='macro')*100)  # micro\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "                train_f1.append(epoch_f1)\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc)\n",
    "                valid_f1.append(epoch_f1)\n",
    "\n",
    "            print('{} Loss: {:.2f} | Acc: {:.2f} | f1: {:.2f}'.format(phase, epoch_loss, epoch_acc, epoch_f1))\n",
    "\n",
    "            # save best model, validation acc가 높을때 저장, deep copy the model\n",
    "    #         if (phase == 'valid') and (epoch_acc > best_acc):\n",
    "            if (phase == 'valid') and (epoch_f1 > best_f1):            \n",
    "                best_idx = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_f1  = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    #                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
    "                print('==> best model saved - %d | %.2f | %.2f'%(best_idx, best_acc, best_f1))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: %d - %.2f | %.2f' %(best_idx, best_acc, best_f1))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # multi gpu면 weight key에 'module.'이 붙으므로 떼고 저장\n",
    "    if use_multi_gpu:\n",
    "        model_state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "    weights_path = os.path.join(save_path, 'model_%d_%.2f_%.2f.pt'%(best_idx, best_acc, best_f1))\n",
    "    torch.save(model_state_dict, weights_path)\n",
    "    \n",
    "    print('save model_%d_%.2f_%.2f.pt'%(best_idx, best_acc, best_f1))\n",
    "    return model, best_idx, best_acc, train_loss, train_acc, train_f1, valid_loss, valid_acc, valid_f1, weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train!!\n",
    "model, best_idx, best_acc, train_loss, train_acc, train_f1, valid_loss, valid_acc, valid_f1, weights_path = train_model(\n",
    "    model, criterion, optimizer, scheduler, num_epochs=num_epochs,\n",
    "    is_test=is_Test, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## 결과 그래프 그리기\n",
    "print('Best model valid loss|acc|f1: %d - %.2f | %.2f | %.2f' %(best_idx, valid_loss[best_idx], valid_acc[best_idx], valid_f1[best_idx]))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(train_acc, 'b-')\n",
    "ax1.plot(valid_acc, 'r-')\n",
    "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
    "ax1.set_xlabel('epoch')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('acc', color='k')\n",
    "ax1.tick_params('y', colors='k')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_loss, 'g-')\n",
    "ax2.plot(valid_loss, 'k-')\n",
    "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
    "ax2.set_ylabel('loss', color='k')\n",
    "ax2.tick_params('y', colors='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, 'result.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "weights_path = os.path.join(save_path, 'model_2_38.57_33.66.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## load model for test\n",
    "def load_model_for_test(weights_path, num_classes=2):\n",
    "    \n",
    "    # load best model from weight\n",
    "    # weights_path = 'output_crop/model_4_100.00_100.00.pt'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    ## load model\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    model_name = 'efficientnet-b0'  # b5\n",
    "#     num_classes = 2  # 장싱, 비정상\n",
    "    freeze_extractor = True  # FC layer만 학습하고 efficientNet extractor 부분은 freeze하여 학습시간 단축, 89860 vs 4097408\n",
    "    use_multi_gpu = True\n",
    "\n",
    "    model_load = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "    state_dict = torch.load(weights_path, map_location=device)  # load weight\n",
    "    model_load.load_state_dict(state_dict, strict=False)  # insert weight to model structure\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)            \n",
    "    print('학습 parameters 개수 : %d'%(count_parameters(model_load)))\n",
    "\n",
    "    # multi gpu(2개 이상)를 사용하는 경우\n",
    "    if use_multi_gpu:\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        if (device.type=='cuda') and (num_gpu > 1):\n",
    "            print('use multi gpu : %d' % (num_gpu))\n",
    "            model_load = nn.DataParallel(model_load, device_ids=list(range(num_gpu)))\n",
    "\n",
    "    model_load = model_load.to(device)\n",
    "\n",
    "\n",
    "    # define optimizer, criterion\n",
    "    criterion = nn.CrossEntropyLoss()  # 분류이므로 cross entrophy 사용    \n",
    "    \n",
    "    return model_load, criterion, device\n",
    "\n",
    "model_load, criterion, device = load_model_for_test(weights_path, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# get_test_metric\n",
    "def get_test_metric(model, phase = 'test', num_images=4, device='cuda', is_Test=False):\n",
    "\n",
    "    ## 데이타 체크\n",
    "    def imshow(inp, title=None):\n",
    "        \"\"\"Imshow for Tensor.\"\"\"\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        plt.imshow(inp)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "        \n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "    pred_list, label_list = [], []  \n",
    "\n",
    "    dataloader = dataloaders[phase]\n",
    "    allFiles, _ = map(list, zip(*dataloader.dataset.dataset.samples))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "\n",
    "            if is_Test:\n",
    "                if idx > 2: break\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
    "\n",
    "            running_loss    += loss.item() * inputs.size(0)\n",
    "            running_corrects+= torch.sum(preds == labels.data)\n",
    "            num_cnt += inputs.size(0)  # batch size\n",
    "\n",
    "            pred_list  += preds.data.cpu().numpy().tolist()\n",
    "            label_list += labels.data.cpu().numpy().tolist()\n",
    "\n",
    "        test_loss = running_loss / num_cnt\n",
    "        test_acc  = running_corrects.double() / num_cnt\n",
    "        test_f1   = float(f1_score(label_list, pred_list, average='macro'))  # micro    \n",
    "        print('test done : loss|acc|f1 : %.3f | %.2f | %.2f ' % (test_loss, test_acc*100, test_f1*100))\n",
    "    \n",
    "    ## 예시 그림 plot\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)        \n",
    "                \n",
    "            # 예시 그림 plot\n",
    "            for j in range(1, num_images+1):\n",
    "                ax = plt.subplot(num_images//2, 2, j)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('%s : %s -> %s'%(\n",
    "                    'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False!!!',\n",
    "                    class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                print(allFiles[ i * batch_size + j -1])            \n",
    "            if i == 0 : break\n",
    "\n",
    "    return label_list, pred_list\n",
    "\n",
    "\n",
    "## TEST!\n",
    "label_list, outputs_list = get_test_metric(model=model_load, num_images=4, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## efficient net\n",
    "print('!!!!!! load done, efficient net!!')\n",
    "features_fn  = model_load.module.features_fn\n",
    "classifier_fn= model_load.module.classifier_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def GradCAM(img, class_idx, features_fn, classifier_fn):\n",
    "\n",
    "    feature = features_fn(img.cuda())  # A, [1, 1280, 7, 7]\n",
    "    _, N, H, W = feature.size()  # 1280, 7, 7\n",
    "    out = classifier_fn(feature)  # shape : [1, 7] - [-2.6593, -5.3088, -2.2299, -1.2445,  2.3712, -2.7554, 11.4827]\n",
    "    class_score = out[0, class_idx]  # class_idxc=6이면 심상정일 때의 score, 11.4827\n",
    "\n",
    "    # gradients via back-propagation\n",
    "    # 특정 클래스(class_idx)의 gradient (dy/dA)\n",
    "    # 최종단과 feature단의 미분값을 구한다\n",
    "    grads = torch.autograd.grad(class_score, feature)  # grads = K.gradients(y_c, layer_output)[0]\n",
    "\n",
    "    # a_k_c, Global average pooling\n",
    "    weights = torch.mean(grads[0][0], axis=(1,2))  # (1280, 7, 7) -> (1280)\n",
    "\n",
    "    ####################################################\n",
    "    ## 1. torch 방법\n",
    "    heatmap = torch.matmul(weights, feature.view(N, H*W))  # liniear combination : a_k_c * A__k, 1280 * (1280, 49)\n",
    "    heatmap = heatmap.view(H, W).cpu().detach().numpy()  # (7, 7)\n",
    "    ####################################################\n",
    "    ## 2. 다른 방법 - https://github.com/jacobgil/pytorch-grad-cam/blob/master/gradcam.py\n",
    "    # target = feature[0].cpu().data.numpy()\n",
    "    # heatmap = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "    # for i, w in enumerate(weights):\n",
    "    #     heatmap += w.cpu().data.numpy() * target[i, :, :]\n",
    "    ####################################################\n",
    "    grad_cam = np.maximum(heatmap, 0)  # ReLU, 0보다 큰값만 살린다\n",
    "    # 0~1 사이로 정규화\n",
    "    grad_cam -= grad_cam.min()\n",
    "    grad_cam /= grad_cam.max()\n",
    "    \n",
    "    return grad_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Opens image from disk, normalizes it and converts to tensor\n",
    "read_image_to_tensor = transforms.Compose([\n",
    "    lambda x: Image.open(x),\n",
    "#     lambda x: x.convert('RGB'),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "    lambda x: torch.unsqueeze(x, 0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plot GradCAM\n",
    "import glob\n",
    "imshow_number = 10\n",
    "top_k = 3\n",
    "\n",
    "def plot_gradcam(data_path, class_label=0, top_k=3, imshow_number=5):\n",
    "#     class_label = 0  # 0: 이재명, ..\n",
    "    folder_path = os.path.join(data_path, sorted(os.listdir(os.path.join(data_path)))[class_label])  # 'data/data_president/1_이재명'\n",
    "\n",
    "    # img_path = 'data/data_president/1_이재명/naver_0383.jpg'\n",
    "\n",
    "    model_load.eval()  # 가장중요!! 이거 안하면 계속 모델 weight가 바뀐다ㅠ\n",
    "    for img_path in  glob.glob(os.path.join(folder_path, '*.jpg'))[:imshow_number]:\n",
    "        img_tensor = read_image_to_tensor(img_path)\n",
    "        output = model_load(img_tensor.to(device))  # tensor([[-2.6664,  2.5967]])\n",
    "        output_softmax = nn.Softmax(dim=1)(output)  # tensor([[0.0094, 0.9906]]\n",
    "        class_probability, class_idx = torch.topk(output_softmax, top_k)  # top1: (tensor([[0.9944]]), tensor([[1]])), tok2라면 ([[0.9819, 0.0181]], [[1, 0]])\n",
    "        # pp, cc = torch.topk(nn.Softmax(dim=1)(model_load(img_tensor.cuda())), 1)  # 3->1\n",
    "\n",
    "        class_label_string = class_names['%s'%(class_label)]\n",
    "        class_idx_string = class_names['%s'%(class_idx.cpu().numpy()[0][0])]\n",
    "        class_probability_string = class_probability.cpu().tolist()[0][0]\n",
    "\n",
    "        print('%s: %s -> %s (%.2f)'%(('True' if class_label==class_idx.cpu().numpy()[0][0] else '!!!Fail!!!'), class_label_string, class_idx_string, class_probability_string*100))\n",
    "\n",
    "        # plot GradCAM\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, (p, c) in enumerate(zip(class_probability[0], class_idx[0])):\n",
    "            plt.subplot(1, top_k, i+1)\n",
    "            grad_cam = GradCAM(img_tensor, int(c), features_fn, classifier_fn)  # 7x7\n",
    "            img = Image.open(img_path)\n",
    "            grad_cam = Image.fromarray(grad_cam)\n",
    "            grad_cam = grad_cam.resize(img.size, resample=Image.LINEAR)  # 7x7 -> 224x224\n",
    "    #         print(i, p, c, str(int(c.cpu())))\n",
    "            plt.title('{}: {:.1f}%'.format(class_names[str(int(c.cpu()))], 100*float(p)))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(np.array(grad_cam), alpha=0.5, cmap='jet')        \n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "plot_gradcam(data_path, class_label=0, top_k=top_k, imshow_number=imshow_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_gradcam(data_path, class_label=1, top_k=top_k, imshow_number=imshow_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_gradcam(data_path, class_label=2, top_k=top_k, imshow_number=imshow_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack\n",
    "\n",
    "1) FGSM(Fast Gradient Sign Method)\n",
    "\n",
    "모델의 파라미터를 바꿔가면서 예측 비용이 가장 낮아지는 지점을 찾는다. FGSM에서는 모델은 이미 학습이 끝난 상태이므로 파라미터가 고정되고 데이터에 조작을 가한다. 그리고 예측 비용이 가장 높아지는 방향, 즉 모델이 최대한 오답을 내도록 이미지를 변형\n",
    "\n",
    "- https://leedakyeong.tistory.com/entry/%EB%85%BC%EB%AC%B8-FGSM-%EB%A6%AC%EB%B7%B0-EXPLAINING-AND-HARNESSING-ADVERSARIAL-EXAMPLES\n",
    "- https://rain-bow.tistory.com/entry/Adversarial-Attack\n",
    "- https://github.com/Jeffkang-94/pytorch-adversarial-attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(save_path, 'model_2_38.57_33.66.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "## load model for test\n",
    "def load_model_for_test(weights_path, num_classes=2):\n",
    "    \n",
    "    # load best model from weight\n",
    "    # weights_path = 'output_crop/model_4_100.00_100.00.pt'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    ## load model\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    model_name = 'efficientnet-b0'  # b5\n",
    "#     num_classes = 2  # 장싱, 비정상\n",
    "    freeze_extractor = True  # FC layer만 학습하고 efficientNet extractor 부분은 freeze하여 학습시간 단축, 89860 vs 4097408\n",
    "    use_multi_gpu = True\n",
    "\n",
    "    model_load = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "    state_dict = torch.load(weights_path, map_location=device)  # load weight\n",
    "    model_load.load_state_dict(state_dict, strict=False)  # insert weight to model structure\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)            \n",
    "    print('학습 parameters 개수 : %d'%(count_parameters(model_load)))\n",
    "\n",
    "    # multi gpu(2개 이상)를 사용하는 경우\n",
    "    if use_multi_gpu:\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        if (device.type=='cuda') and (num_gpu > 1):\n",
    "            print('use multi gpu : %d' % (num_gpu))\n",
    "            model_load = nn.DataParallel(model_load, device_ids=list(range(num_gpu)))\n",
    "\n",
    "    model_load = model_load.to(device)\n",
    "\n",
    "\n",
    "    # define optimizer, criterion\n",
    "    criterion = nn.CrossEntropyLoss()  # 분류이므로 cross entrophy 사용    \n",
    "    \n",
    "    return model_load, criterion, device\n",
    "\n",
    "model_load, criterion, device = load_model_for_test(weights_path, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "aa_model = model_load  # model 저장\n",
    "aa_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 그림 plot\n",
    "phase = 'test'\n",
    "img_idx = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs, labels = next(iter(dataloaders['test']))        \n",
    "        \n",
    "img_tensor, label = inputs.to(device), labels.to(device)\n",
    "img_batch = img_tensor[img_idx].unsqueeze(0)  # [1, 3, 224, 224]\n",
    "# label_batch = label[0]  # tensor(0, device='cuda:0')\n",
    "label_batch = label[img_idx:img_idx+1]  # tensor([0], device='cuda:0')\n",
    "\n",
    "# 입력 이미지의 gradient를 구해야 하므로 requires_grad를 True로 설정한다.\n",
    "img_batch.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 결과를 얻는다.\n",
    "logits = aa_model(img_batch)  # [16.2607, -5.2704, -4.4725, -3.5213, -2.5452, -2.0208,  1.8761]\n",
    "probs = F.softmax(logits, dim=1)[0]  # [1.0000e+00, 4.4582e-10, 9.9018e-10, ..]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용을 계산하고\n",
    "# backpropagation을 실행한다.\n",
    "cost_fn = nn.CrossEntropyLoss()\n",
    "cost = cost_fn(logits, label_batch)  # tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n",
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용에 대한 원본 이미지의 gradient를 구한다.\n",
    "grad = img_batch.grad.detach()[0] # ▽xJ(θ,x,y), batch 차원을 없앤다. # [3, 224, 224]\n",
    "signed_grad = torch.sign(grad)    # sign(▽xJ(θ,x,y)), 부호만 살린다. 양수는 1, 음수는 -1, # [3, 224, 224]\n",
    "epsilon = 0.1                     # ϵ = epsilon\n",
    "eta = epsilon * signed_grad       # η = ϵ*sign(▽xJ(θ,x,y), -0.1, +0.1 값을 갖는 행렬, [3, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 이미지에 perturbation을 가해 Adversarial Example을 만든다.\n",
    "img_hat_batch = img_batch + eta # x_=x+η"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch[0][0][0][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta[0][0][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hat_batch[0][0][0][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## 데이타 체크 함수\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 이미지 체크\n",
    "imshow(img_batch[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial attack 체크\n",
    "imshow(signed_grad.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본이미지 + adversarial attack 체크\n",
    "imshow(img_hat_batch[0].cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## 분류 결과 차이 비교\n",
    "# 정상 분류 결과\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "fig.subplots_adjust(wspace=50)\n",
    "colors = sns.color_palette('pastel', len(list(class_names.values())))\n",
    "\n",
    "logits = aa_model(img_batch)  # [16.2607, -5.2704, -4.4725, -3.5213, -2.5452, -2.0208,  1.8761]\n",
    "probs = F.softmax(logits, dim=1)[0]  # [1.0000e+00, 4.4582e-10, 9.9018e-10, ..]\n",
    "# plt.bar(['chu', 'hong', 'hwang', 'myung', 'yeon', 'park', 'sim'], list(probs.cpu().data.numpy()))\n",
    "axs[0].bar(list(class_names.values()), list(probs.cpu().data.numpy()), color=colors, edgecolor=colors, alpha=0.7, linewidth=2)\n",
    "axs[0].set_title('base model')\n",
    "axs[0].set_ylabel('Probability')\n",
    "print(probs)\n",
    "# AA분류 결과\n",
    "aa_logits = aa_model(img_hat_batch)  # [16.2607, -5.2704, -4.4725, -3.5213, -2.5452, -2.0208,  1.8761]\n",
    "aa_probs = F.softmax(aa_logits, dim=1)[0]  # [1.0000e+00, 4.4582e-10, 9.9018e-10, ..]\n",
    "axs[1].bar(list(class_names.values()), list(aa_probs.cpu().data.numpy()), color=colors, edgecolor=colors, alpha=0.7, linewidth=2)\n",
    "axs[1].set_title('AA model')\n",
    "axs[1].set_ylabel('Probability')\n",
    "print(aa_probs)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot GradCAM on Original input\n",
    "img_tensor = img_batch\n",
    "pp, cc = torch.topk(nn.Softmax(dim=1)(aa_model(img_tensor)), 1)  # 3->1\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (p, c) in enumerate(zip(pp[0], cc[0])):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    grad_cam = GradCAM(img_tensor, int(c), features_fn, classifier_fn)  # 7x7\n",
    "#     img = Image.open(img_path)\n",
    "\n",
    "    # tensor to img\n",
    "    inp = img_tensor[0].cpu().detach()\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "    grad_cam = Image.fromarray(grad_cam)\n",
    "    grad_cam = grad_cam.resize((224, 224), resample=Image.LINEAR)  # 7x7 -> 224x224\n",
    "\n",
    "    plt.title('{}: {:.1f}%'.format(class_names[str(int(c.cpu()))], 100*float(p)))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(grad_cam), alpha=0.5, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot GradCAM on adversarial example input\n",
    "img_tensor = img_hat_batch\n",
    "\n",
    "pp, cc = torch.topk(nn.Softmax(dim=1)(aa_model(img_tensor)), 1)  # 3->1\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (p, c) in enumerate(zip(pp[0], cc[0])):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    grad_cam = GradCAM(img_tensor, int(c), features_fn, classifier_fn)  # 7x7\n",
    "#     img = Image.open(img_path)\n",
    "\n",
    "    # tensor to img\n",
    "    inp = img_tensor[0].cpu().detach()\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "    grad_cam = Image.fromarray(grad_cam)\n",
    "    grad_cam = grad_cam.resize((224, 224), resample=Image.LINEAR)  # 7x7 -> 224x224\n",
    "\n",
    "    plt.title('{}: {:.1f}%'.format(class_names[str(int(c.cpu()))], 100*float(p)))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(grad_cam), alpha=0.5, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Adversarial Attaact\n",
    "\n",
    "###### https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demos/White%20Box%20Attack%20(ImageNet).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(save_path, 'model_2_38.57_33.66.pt')\n",
    "batch_size = 50\n",
    "number_show_image = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "## load model for test\n",
    "def load_model_for_test(weights_path, num_classes=2):\n",
    "    \n",
    "    # load best model from weight\n",
    "    # weights_path = 'output_crop/model_4_100.00_100.00.pt'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    ## load model\n",
    "    from efficientnet_pytorch import EfficientNet\n",
    "    model_name = 'efficientnet-b0'  # b5\n",
    "#     num_classes = 2  # 장싱, 비정상\n",
    "    freeze_extractor = True  # FC layer만 학습하고 efficientNet extractor 부분은 freeze하여 학습시간 단축, 89860 vs 4097408\n",
    "    use_multi_gpu = True\n",
    "\n",
    "    model_load = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n",
    "    state_dict = torch.load(weights_path, map_location=device)  # load weight\n",
    "    model_load.load_state_dict(state_dict, strict=False)  # insert weight to model structure\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)            \n",
    "    print('학습 parameters 개수 : %d'%(count_parameters(model_load)))\n",
    "\n",
    "    # multi gpu(2개 이상)를 사용하는 경우\n",
    "    if use_multi_gpu:\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        if (device.type=='cuda') and (num_gpu > 1):\n",
    "            print('use multi gpu : %d' % (num_gpu))\n",
    "            model_load = nn.DataParallel(model_load, device_ids=list(range(num_gpu)))\n",
    "\n",
    "    model_load = model_load.to(device)\n",
    "\n",
    "\n",
    "    # define optimizer, criterion\n",
    "    criterion = nn.CrossEntropyLoss()  # 분류이므로 cross entrophy 사용    \n",
    "    \n",
    "    return model_load, criterion, device\n",
    "\n",
    "model_load, criterion, device = load_model_for_test(weights_path, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## load liabrary\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import adversarial_attacks_pytorch.torchattacks\n",
    "from adversarial_attacks_pytorch.demos.utils import imshow, imshow_both, image_folder_custom_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## prepare data\n",
    "# make dataset\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Subset, dataloader\n",
    "\n",
    "\n",
    "# transform_function = transforms.Compose([transforms.Resize((224, 224)),  # 모델 입력사이즈로 resize\n",
    "#                                          transforms.ToTensor(),\n",
    "#                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#                                         ])\n",
    "## AA는 입력이 0~1인 상태에서 공격하므로 normalize는 뒤에서 하자\n",
    "transform_function_aa = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                            transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n",
    "#                                             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                           ])\n",
    "\n",
    "# class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
    "dataset_aa = datasets.ImageFolder(data_path,\n",
    "                               transform_function_aa)\n",
    "\n",
    "# make 8:1:1 idx & dataset\n",
    "random_seed = 220103\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random_idx = list(range(0, len(dataset_aa)))\n",
    "random.shuffle(random_idx)\n",
    "print('total data num : %d'%len(random_idx))\n",
    "print('random check : %s'%random_idx[:5])\n",
    "\n",
    "proportion = [8, 1, 1]  ## !! 이 부분을 6, 2, 2로 바꾸면 train/valid/test 비율 조정 가능\n",
    "proportion_data = [tmp*int(len(random_idx)/10) for tmp in proportion]\n",
    "# assert sum(proportion_data) == len(random_idx)  # 반올림해서 총합은 틀려진다\n",
    "\n",
    "train_idx = random_idx[:proportion_data[0]]\n",
    "valid_idx = random_idx[proportion_data[0] : proportion_data[0]+proportion_data[1]]\n",
    "test_idx  = random_idx[proportion_data[0]+proportion_data[1] :]\n",
    "\n",
    "print('data proportion(train:valid:test) = %s : %s : %s'%(len(train_idx), len(valid_idx), len(test_idx)))\n",
    "\n",
    "datasets_aa = {}\n",
    "datasets_aa['train'] = Subset(dataset_aa, train_idx)\n",
    "datasets_aa['valid'] = Subset(dataset_aa, valid_idx)\n",
    "datasets_aa['test']  = Subset(dataset_aa, test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## data loader 선언\n",
    "dataloaders_aa, batch_num_aa = {}, {}\n",
    "dataloaders_aa['train'] = torch.utils.data.DataLoader(datasets_aa['train'],\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "dataloaders_aa['valid'] = torch.utils.data.DataLoader(datasets_aa['valid'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "dataloaders_aa['test']  = torch.utils.data.DataLoader(datasets_aa['test'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "batch_num_aa['train'], batch_num_aa['valid'], batch_num_aa['test'] = len(dataloaders_aa['train']), len(dataloaders_aa['valid']), len(dataloaders_aa['test'])\n",
    "print('batch_size : %d,  number of batch(tvt) : %d / %d / %d' % (batch_size, batch_num_aa['train'], batch_num_aa['valid'], batch_num_aa['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## data check\n",
    "images, labels = iter(dataloaders_aa['test']).next()\n",
    "\n",
    "print(\"True Image & True Label\")\n",
    "imshow(make_grid(images[:number_show_image], normalize=True), [list(class_names.values())[i] for i in labels[:number_show_image]])  # n개만 그리자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## prepare model \n",
    "# transform에서 normalize하던걸 떼어내서 model의 앞에 부친다. AA는 입력이 0~1이어야 하므로\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std) :\n",
    "        super(Normalize, self).__init__()\n",
    "        self.register_buffer('mean', torch.Tensor(mean))\n",
    "        self.register_buffer('std', torch.Tensor(std))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Broadcasting\n",
    "        mean = self.mean.reshape(1, 3, 1, 1)\n",
    "        std = self.std.reshape(1, 3, 1, 1)\n",
    "        return (input - mean) / std\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Adding a normalization layer for Resnet18.\n",
    "# We can't use torch.transforms because it supports only non-batch images.\n",
    "norm_layer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "model = nn.Sequential(norm_layer, \n",
    "                      model_load  # 학습한 EfficientNet\n",
    "                     ).to(device)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## load attacker\n",
    "# from adversarial_attacks_pytorch.torchattacks import *\n",
    "from adversarial_attacks_pytorch.torchattacks.attacks.fgsm import FGSM\n",
    "from adversarial_attacks_pytorch.torchattacks.attacks.pgd import PGD\n",
    "\n",
    "atks = [\n",
    "    FGSM(model, eps=8/255),\n",
    "#     BIM(model, eps=8/255, alpha=2/255, steps=100),\n",
    "#     RFGSM(model, eps=8/255, alpha=2/255, steps=100),\n",
    "#     CW(model, c=1, lr=0.01, steps=100, kappa=0),\n",
    "    PGD(model, eps=8/255, alpha=2/225, steps=100, random_start=True),\n",
    "#     PGDL2(model, eps=1, alpha=0.2, steps=100),\n",
    "#     EOTPGD(model, eps=8/255, alpha=2/255, steps=100, eot_iter=2),\n",
    "#     FFGSM(model, eps=8/255, alpha=10/255),\n",
    "#     TPGD(model, eps=8/255, alpha=2/255, steps=100),\n",
    "#     MIFGSM(model, eps=8/255, alpha=2/255, steps=100, decay=0.1),\n",
    "#     VANILA(model),\n",
    "#     GN(model, std=0.1),\n",
    "#     APGD(model, eps=8/255, steps=100, eot_iter=1, n_restarts=1, loss='ce'),\n",
    "#     APGD(model, eps=8/255, steps=100, eot_iter=1, n_restarts=1, loss='dlr'),\n",
    "#     APGDT(model, eps=8/255, steps=100, eot_iter=1, n_restarts=1),\n",
    "#     FAB(model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=False),\n",
    "#     FAB(model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=True),\n",
    "#     Square(model, eps=8/255, n_queries=5000, n_restarts=1, loss='ce'),\n",
    "#     AutoAttack(model, eps=8/255, n_classes=10, version='standard'),\n",
    "#     OnePixel(model, pixels=5, inf_batch=50),\n",
    "#     DeepFool(model, steps=100),\n",
    "#     DIFGSM(model, eps=8/255, alpha=2/255, steps=100, diversity_prob=0.5, resize_rate=0.9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## attack!\n",
    "print(\"Adversarial Image & Predicted Label\")\n",
    "\n",
    "for atk in atks:\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(atk)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, (images, labels) in enumerate(dataloaders_aa['test']):\n",
    "        \n",
    "        start = time.time()\n",
    "        adv_images = atk(images, labels)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(adv_images)\n",
    "\n",
    "        _, predict = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += len(labels)\n",
    "        correct += (predict == labels).sum()\n",
    "\n",
    "#         imshow(torchvision.utils.make_grid(adv_images.cpu().data[:number_show_image], normalize=True), [list(class_names.values())[i] for i in predict[:number_show_image]])  # n개만 그리자\n",
    "        imshow_both(make_grid(images.cpu().data[:number_show_image],normalize=True),\n",
    "                    make_grid(adv_images.cpu().data[:number_show_image],normalize=True),\n",
    "                    [list(class_names.values())[i] for i in predict[:number_show_image]])  # n개만 그리자\n",
    "        \n",
    "        if idx == 0 : break  # 첫 배치만 돌리자\n",
    "        \n",
    "    print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "    print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
